{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "835858fc",
   "metadata": {},
   "source": [
    "# Score Calculator\n",
    "Automatically computes the **Coherence Score Φ** from your indicators and latest data.\n",
    "\n",
    "Prerequisites:\n",
    "```bash\n",
    "pip install pandas pyyaml\n",
    "```\n",
    "\n",
    "Folder layout assumed:\n",
    "```\n",
    "community-conflict-guide/\n",
    "  indicators.yaml\n",
    "  data/\n",
    "      processed/\n",
    "          *.csv  # one CSV per indicator, latest measurement already aggregated\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml, json, glob, os\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a4d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load indicator definitions\n",
    "with open('indicators.yaml', 'r') as f:\n",
    "    ind = yaml.safe_load(f)\n",
    "print('Indicators:')\n",
    "pprint(ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55095d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/processed'\n",
    "values = {}\n",
    "for metric in ind:\n",
    "    file_pattern = os.path.join(data_dir, f'{metric}*.csv')\n",
    "    files = sorted(glob.glob(file_pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f'No data file found for {metric}')\n",
    "    # use the latest by alphabetical order (timestamp prefix recommended)\n",
    "    latest = files[-1]\n",
    "    df = pd.read_csv(latest)\n",
    "    # expecting a single value column called 'value'\n",
    "    val = df['value'].iloc[-1]\n",
    "    values[metric] = float(val)\n",
    "\n",
    "print('Latest measurements:')\n",
    "pprint(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ff5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches = {}\n",
    "for metric, info in ind.items():\n",
    "    current = values[metric]\n",
    "    target = info['target']\n",
    "    weight = info['weight']\n",
    "    mismatch = abs(current - target) / target\n",
    "    mismatches[metric] = {'value': current, 'target': target, 'weight': weight, 'mismatch': mismatch}\n",
    "\n",
    "score = sum(d['weight'] * d['mismatch'] for d in mismatches.values())\n",
    "print(f'\\nCoherence Score Φ = {score:.4f}\\n')\n",
    "pd.DataFrame(mismatches).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21436d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "log_dir = 'logs'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "timestamp = datetime.utcnow().strftime('%Y-%m-%dT%H%M%SZ')\n",
    "log_path = os.path.join(log_dir, f'{timestamp}.csv')\n",
    "row = {'timestamp': timestamp, 'score': score}\n",
    "row.update({f'{m}_value': d['value'] for m, d in mismatches.items()})\n",
    "pd.DataFrame([row]).to_csv(log_path, index=False)\n",
    "print(f'Logged to {log_path}')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
